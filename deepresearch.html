<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Deep Research Assistant - Multi-site</title>
<script src="https://js.puter.com/v2/"></script>
<script src="https://cdn.jsdelivr.net/npm/@mendable/firecrawl-js"></script>
<style>
  body { font-family: Arial, sans-serif; margin: 2rem; }
  #output { white-space: pre-wrap; margin-top: 1rem; max-height: 600px; overflow-y: auto; }
</style>
</head>
<body>

<h1>Deep Research Assistant</h1>

<input id="topicInput" type="text" placeholder="Enter research topic" style="width: 60%;" />
<button id="searchBtn">Search & Research</button>

<div id="output"></div>

<script>
  const firecrawlApp = new FirecrawlApp({ apiKey: "fc-999bd998d54a43498eb3559311ad94da" });

  // DuckDuckGo JSON search API (unofficial, limited)
  async function ddgSearch(query) {
    const url = `https://duckduckgo.com/html/?q=${encodeURIComponent(query)}`;
    // Using a CORS proxy because duckduckgo.com/html does not allow CORS
    const proxy = "https://api.allorigins.win/get?url=" + encodeURIComponent(url);
    const res = await fetch(proxy);
    if (!res.ok) throw new Error("Failed to fetch search results");
    const data = await res.json();
    // Extract links from the HTML using DOMParser
    const parser = new DOMParser();
    const doc = parser.parseFromString(data.contents, "text/html");
    const results = Array.from(doc.querySelectorAll(".result__a"))
      .map(a => a.href)
      .filter(href => href.startsWith("http"));
    return results.slice(0, 5); // limit to top 5 results
  }

  async function deepResearch(topic) {
    const outputEl = document.getElementById("output");
    outputEl.textContent = "Searching web for relevant websites...";
    try {
      // 1. Search DuckDuckGo for URLs
      const urls = await ddgSearch(topic);
      if (urls.length === 0) {
        outputEl.textContent = "No results found for your topic.";
        return;
      }
      outputEl.textContent = `Found ${urls.length} URLs. Crawling pages...`;

      // 2. Crawl each URL with Firecrawl (limit 3 pages per URL)
      let allContent = "";
      for (const url of urls) {
        try {
          const crawlRes = await firecrawlApp.crawlUrl(url, {
            limit: 3,
            scrapeOptions: { formats: ["markdown", "text"] },
          });
          if (crawlRes.success) {
            const pageTexts = crawlRes.data.map(page => page.content).join("\n\n---\n\n");
            allContent += `\n\n--- Content from: ${url} ---\n\n` + pageTexts;
          } else {
            console.warn(`Failed to crawl ${url}: ${crawlRes.error}`);
          }
        } catch (e) {
          console.warn(`Error crawling ${url}:`, e);
        }
      }

      if (!allContent) {
        outputEl.textContent = "No content could be crawled from search results.";
        return;
      }

      outputEl.textContent = "Generating detailed AI research summary...";

      // 3. Use Puter.js AI to answer with all collected content
      const aiResponse = await puter.ai.chat([
        { role: "system", content: "You are an expert research assistant." },
        { role: "user", content: `Based on the following combined content from multiple websites, provide a detailed and coherent answer on the topic: ${topic}\n\n${allContent}` }
      ], { model: "gpt-4.1-nano" });

      outputEl.textContent = aiResponse;

    } catch (err) {
      console.error(err);
      outputEl.textContent = "Error: " + err.message;
    }
  }

  document.getElementById("searchBtn").addEventListener("click", () => {
    const topic = document.getElementById("topicInput").value.trim();
    if (!topic) {
      alert("Please enter a research topic.");
      return;
    }
    deepResearch(topic);
  });
</script>

</body>
</html>

